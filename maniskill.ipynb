{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dadf67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import yaml\n",
    "import pathlib\n",
    "from types import SimpleNamespace # Used to mimic argparse.Namespace\n",
    "import mani_skill\n",
    "import exploration as expl\n",
    "import models\n",
    "import tools\n",
    "import envs.wrappers as wrappers\n",
    "from parallel import Parallel, Damy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions as torchd\n",
    "import datetime\n",
    "to_np = lambda x: x.detach().cpu().numpy()\n",
    "from dreamer import make_env, count_steps, Dreamer, make_dataset\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4adb01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration Loading ---\n",
    "def recursive_update(base, update):\n",
    "    \"\"\"Recursively updates a dictionary `base` with values from `update`.\"\"\"\n",
    "    for key, value in update.items():\n",
    "        if isinstance(value, dict) and key in base:\n",
    "            recursive_update(base[key], value)\n",
    "        else:\n",
    "            base[key] = value\n",
    "\n",
    "def load_configs(config_names=None):\n",
    "    \"\"\"\n",
    "    Loads configurations from 'configs.yaml', applying defaults and\n",
    "    specified overrides.\n",
    "    \"\"\"\n",
    "    # Adjust this path if configs.yaml is not in the same directory\n",
    "    config_path = pathlib.Path(\"~/dreamerv3-torch/configs.yaml\").expanduser()\n",
    "    \n",
    "    if not config_path.exists():mani_skill\n",
    "    all_configs = yaml.safe_load(config_path.read_text())\n",
    "\n",
    "    name_list = [\"defaults\", *config_names] if config_names else [\"defaults\"]\n",
    "    \n",
    "    final_config = {}\n",
    "    for name in name_list:\n",
    "        if name not in all_configs:\n",
    "            print(f\"Warning: Configuration '{name}' not found in configs.yaml. Skipping.\")\n",
    "            continue\n",
    "        recursive_update(final_config, all_configs[name])\n",
    "    \n",
    "\n",
    "    for k,v in final_config.items():\n",
    "        if isinstance(v, dict): # TODO: only one level, need recurse\n",
    "            for dk, dv in v.items():\n",
    "                v[dk] = tools.args_type(dv)(dv)\n",
    "        else:\n",
    "            final_config[k] = tools.args_type(v)(v)\n",
    "\n",
    "    # Convert the dictionary to a SimpleNamespace to mimic argparse.Namespace\n",
    "    return SimpleNamespace(**final_config)\n",
    "\n",
    "\n",
    "\n",
    "# --- Mimicking Command Line Arguments (for Jupyter) ---\n",
    "config = load_configs(config_names=['maniskill'])\n",
    "# config = load_configs(config_names=['dmc_vision'])\n",
    "\n",
    "print(config.task, config.units, type(config.actor['lr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1411cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.set_seed_everywhere(config.seed)\n",
    "if config.deterministic_run:\n",
    "    tools.enable_deterministic_run()\n",
    "\n",
    "if not config.logdir:\n",
    "    config.logdir = f\"./logs/{datetime.datetime.now().strftime(format='%d_%m_%y/%H:%M:%S')}\"\n",
    "    \n",
    "logdir = pathlib.Path(config.logdir).expanduser()\n",
    "config.traindir = config.traindir or logdir / \"train_eps\"\n",
    "config.demodir = config.traindir or logdir / \"demo_eps\"\n",
    "config.evaldir = config.evaldir or logdir / \"eval_eps\"\n",
    "config.steps //= config.action_repeat\n",
    "config.eval_every //= config.action_repeat\n",
    "config.log_every //= config.action_repeat\n",
    "config.time_limit //= config.action_repeat\n",
    "\n",
    "if type(config.logdir) == str: config.traindir = pathlib.Path(config.traindir)\n",
    "if type(config.demodir) == str: config.demodir =  pathlib.Path(config.demodir)\n",
    "\n",
    "print(\"Logdir\", logdir, )\n",
    "logdir.mkdir(parents=True, exist_ok=True)\n",
    "config.traindir.mkdir(parents=True, exist_ok=True)\n",
    "config.evaldir.mkdir(parents=True, exist_ok=True)\n",
    "config.demodir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "step = count_steps(config.traindir) + count_steps(config.demodir)\n",
    "# step in logger is environmental step\n",
    "logger = tools.Logger(logdir, config.action_repeat * step)\n",
    "\n",
    "print(\"Create envs.\")\n",
    "if config.offline_traindir:\n",
    "    directory = config.offline_traindir.format(**vars(config))\n",
    "else:\n",
    "    directory = config.traindir\n",
    "train_eps = tools.load_episodes(directory, limit=100) #config.dataset_size)\n",
    "\n",
    "if config.offline_evaldir:\n",
    "    directory = config.offline_evaldir.format(**vars(config))\n",
    "else:\n",
    "    directory = config.evaldir\n",
    "eval_eps = tools.load_episodes(directory, limit=1)\n",
    "\n",
    "demo_eps = tools.load_episodes(config.demodir, limit=None)\n",
    "\n",
    "make = lambda mode, id: make_env(config, mode, id)\n",
    "train_envs = [make(\"train\", i) for i in range(config.envs)]\n",
    "eval_envs = [make(\"eval\", i) for i in range(config.envs)]\n",
    "if config.parallel:\n",
    "    train_envs = [Parallel(env, \"process\") for env in train_envs]\n",
    "    eval_envs = [Parallel(env, \"process\") for env in eval_envs]\n",
    "else:\n",
    "    train_envs = [Damy(env) for env in train_envs]\n",
    "    eval_envs = [Damy(env) for env in eval_envs]\n",
    "acts = train_envs[0].action_space\n",
    "print(\"Action Space\", acts)\n",
    "config.num_actions = acts.n if hasattr(acts, \"n\") else acts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b6336",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = None\n",
    "if not config.offline_traindir:\n",
    "    prefill = max(0, config.prefill - count_steps(config.traindir))\n",
    "    print(f\"Prefill dataset ({prefill} steps).\")\n",
    "    if hasattr(acts, \"discrete\"):\n",
    "        random_actor = tools.OneHotDist(\n",
    "            torch.zeros(config.num_actions).repeat(config.envs, 1)\n",
    "        )\n",
    "    else:\n",
    "        random_actor = torchd.independent.Independent(\n",
    "            torchd.uniform.Uniform(\n",
    "                torch.tensor(acts.low).repeat(config.envs, 1),\n",
    "                torch.tensor(acts.high).repeat(config.envs, 1),\n",
    "            ),\n",
    "            1,\n",
    "        )\n",
    "\n",
    "    def random_agent(o, d, s):\n",
    "        action = random_actor.sample()\n",
    "        logprob = random_actor.log_prob(action)\n",
    "        return {\"action\": action, \"logprob\": logprob}, None\n",
    "\n",
    "    state = tools.simulate(\n",
    "        random_agent,\n",
    "\n",
    "        train_envs,\n",
    "        train_eps,\n",
    "        config.traindir,\n",
    "        logger,\n",
    "        limit=config.dataset_size,\n",
    "        steps=prefill,\n",
    "    )\n",
    "    logger.step += prefill * config.action_repeat\n",
    "    print(f\"Logger: ({logger.step} steps).\")\n",
    "\n",
    "print(\"Simulate agent.\")\n",
    "train_dataset = make_dataset(train_eps, config)\n",
    "eval_dataset = make_dataset(eval_eps, config)\n",
    "demo_dataset = make_dataset(demo_eps, config)\n",
    "train_envs[0].observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194f71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    env = train_envs[0]\n",
    "    env.reset()()\n",
    "    obs, *_ = env.step({'action': train_envs[0].action_space.sample()})()\n",
    "    for k,v in obs.items():\n",
    "        print(k, v.shape if hasattr(v, 'shape') else type(v)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec30006",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Dreamer(\n",
    "    train_envs[0].observation_space,\n",
    "    train_envs[0].action_space,\n",
    "    config,\n",
    "    logger,\n",
    "    train_dataset,\n",
    "    demo_dataset,\n",
    ").to(config.device)\n",
    "agent.requires_grad_(requires_grad=False)\n",
    "if (logdir / \"latest.pt\").exists():\n",
    "    checkpoint = torch.load(logdir / \"latest.pt\")\n",
    "    agent.load_state_dict(checkpoint[\"agent_state_dict\"])\n",
    "    tools.recursively_load_optim_state_dict(agent, checkpoint[\"optims_state_dict\"])\n",
    "    agent._should_pretrain._once = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c17db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    eval_envs = [make(\"train\", i) for i in range(config.envs)]\n",
    "    eval_envs = [Damy(env) for env in eval_envs]\n",
    "\n",
    "    import numpy as np\n",
    "    from tools import convert\n",
    "\n",
    "    envs = eval_envs\n",
    "    step, episode = 0, 0\n",
    "    done = np.ones(len(envs), bool)\n",
    "    length = np.zeros(len(envs), np.int32)\n",
    "    obs = [None] * len(envs)\n",
    "    agent_state = None\n",
    "    reward = [0] * len(envs)\n",
    "    if done.any():\n",
    "        indices = [index for index, d in enumerate(done) if d]\n",
    "        results = [envs[i].reset() for i in indices]\n",
    "        results = [r() for r in results]\n",
    "        for index, result in zip(indices, results): # NOTE: Michael, does this kill us? (pulls every transition off of the GPU to save it, done below as well.)\n",
    "            t = result.copy()\n",
    "            # for k,v in t.items():\n",
    "            #     print(k, v)\n",
    "            #     convert(v)\n",
    "            t = {k: convert(v) for k, v in t.items()}\n",
    "            # action will be added to transition in add_to_cache\n",
    "            t[\"reward\"] = 0.0\n",
    "            t[\"discount\"] = 1.0\n",
    "            # replace obs with done by initial state\n",
    "            obs[index] = result\n",
    "    obs = {k: np.stack([o[k] for o in obs]) for k in obs[0] if \"log_\" not in k}\n",
    "    for k,v in obs.items():\n",
    "        print(k, v.shape if hasattr(v, 'shape') else v)\n",
    "    if agent_state is None:\n",
    "        latent = action = None\n",
    "    else:\n",
    "        latent, action = agent_state\n",
    "    obs = agent._wm.preprocess(obs)\n",
    "    embed = agent._wm.encoder(obs)\n",
    "    # latent, _ = agent._wm.dynamics.obs_step(latent, action, embed, obs[\"is_first\"])\n",
    "    prev_state = latent; prev_action = action; is_first = obs[\"is_first\"]\n",
    "    # def obs_step(self, prev_state, prev_action, embed, is_first, sample=True):\n",
    "    # initialize all prev_state\n",
    "    if prev_state == None or torch.sum(is_first) == len(is_first):\n",
    "        prev_state = agent._wm.dynamics.initial(len(is_first))\n",
    "        prev_action = torch.zeros(\n",
    "            (len(is_first), agent._wm.dynamics._num_actions), device=agent._wm.dynamics._device\n",
    "        )\n",
    "\n",
    "        if len(embed.shape) > len(prev_action.shape):\n",
    "            prev_state = {k:v.unsqueeze(0) for k,v in prev_state.items()}\n",
    "            # prev_state = prev_state.unsqueeze(0)\n",
    "            prev_action = prev_action.unsqueeze(0)\n",
    "    # overwrite the prev_state only where is_first=True\n",
    "    elif torch.sum(is_first) > 0:\n",
    "        is_first = is_first[:, None]\n",
    "        prev_action *= 1.0 - is_first\n",
    "        init_state = agent._wm.dynamics.initial(len(is_first))\n",
    "        for key, val in prev_state.items():\n",
    "            is_first_r = torch.reshape(\n",
    "                is_first,\n",
    "                is_first.shape + (1,) * (len(val.shape) - len(is_first.shape)),\n",
    "            )\n",
    "            prev_state[key] = (\n",
    "                val * (1.0 - is_first_r) + init_state[key] * is_first_r\n",
    "            )\n",
    "\n",
    "    prior = agent._wm.dynamics.img_step(prev_state, prev_action)\n",
    "    embed.shape, prior[\"deter\"].shape, prev_action.shape, prev_state['stoch'].shape, prev_state[\"deter\"].shape\n",
    "\n",
    "    x = torch.cat([prior[\"deter\"], embed], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad4975",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# logger._videos = {}\n",
    "\n",
    "# make sure eval will be executed once after config.steps\n",
    "agent._step = 0\n",
    "\n",
    "print(\"Create envs.\")\n",
    "if config.offline_traindir:\n",
    "    directory = config.offline_traindir.format(**vars(config))\n",
    "else:\n",
    "    directory = config.traindir\n",
    "train_eps = tools.load_episodes(directory, limit=100) #config.dataset_size)\n",
    "train_dataset = make_dataset(train_eps, config)\n",
    "agent._dataset = train_dataset\n",
    "\n",
    "train_envs = [make(\"train\", i) for i in range(config.envs)]\n",
    "if config.parallel:\n",
    "    train_envs = [Parallel(env, \"process\") for env in train_envs]\n",
    "else:\n",
    "    train_envs = [Damy(env) for env in train_envs]\n",
    "\n",
    "# if config.offline_evaldir:\n",
    "#     directory = config.offline_evaldir.format(**vars(config))\n",
    "# else:\n",
    "#     directory = config.evaldir\n",
    "# eval_eps = tools.load_episodes(directory, limit=1)\n",
    "\n",
    "# eval_dataset = make_dataset(eval_eps, config)\n",
    "# eval_envs = [make(\"train\", i) for i in range(config.envs)]\n",
    "# eval_envs = [Damy(env) for env in eval_envs]\n",
    "\n",
    "while agent._step < config.steps + config.eval_every:\n",
    "    # logger.write()\n",
    "    # if config.eval_episode_num > 0:\n",
    "    #     print(\"Start evaluation.\")\n",
    "    #     eval_policy = functools.partial(agent, training=False)\n",
    "    #     tools.simulate(\n",
    "    #         eval_policy,\n",
    "    #         eval_envs,\n",
    "    #         eval_eps,\n",
    "    #         config.evaldir,\n",
    "    #         logger,\n",
    "    #         is_eval=True,\n",
    "    #         episodes=config.eval_episode_num,\n",
    "    #     )\n",
    "        # if config.video_pred_log:\n",
    "        #     d = next(eval_dataset)\n",
    "        #     video_pred = agent._wm.video_pred(d)\n",
    "        #     logger.video(\"eval_openl\", to_np(video_pred))\n",
    "    print(\"Start training.\")\n",
    "    state = tools.simulate(\n",
    "        agent,\n",
    "        train_envs,\n",
    "        train_eps,\n",
    "        config.traindir,\n",
    "        logger,\n",
    "        limit=config.dataset_size,\n",
    "        steps=config.eval_every,\n",
    "        state=state,\n",
    "    )\n",
    "    items_to_save = {\n",
    "        \"agent_state_dict\": agent.state_dict(),\n",
    "        \"optims_state_dict\": tools.recursively_collect_optim_state_dict(agent),\n",
    "    }\n",
    "    torch.save(items_to_save, logdir / \"latest.pt\")\n",
    "for env in train_envs + eval_envs:\n",
    "    try:\n",
    "        env.close()\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac89381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_eps = tools.load_episodes(directory, limit=100) #config.dataset_size)\n",
    "# train_dataset = make_dataset(train_eps, config)\n",
    "d = next(train_dataset)\n",
    "data = agent._wm.preprocess(d)\n",
    "agent._wm.encoder(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208157cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in eval_eps.items():\n",
    "    print(k, v['reward'].__len__())\n",
    "    print(v['image'][0].shape)\n",
    "    print(v['state'][0].shape)\n",
    "\n",
    "print(\"Create envs.\")\n",
    "if config.offline_traindir:\n",
    "    directory = config.offline_traindir.format(**vars(config))\n",
    "else:\n",
    "    directory = config.traindir\n",
    "train_eps = tools.load_episodes(directory, limit=100) #config.dataset_size)\n",
    "train_dataset = make_dataset(train_eps, config)\n",
    "\n",
    "d = next(train_dataset)\n",
    "print(k, d['reward'].__len__())\n",
    "print(d['image'].shape)\n",
    "print(d['state'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e3f43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = next(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845668ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in d.items():\n",
    "    print(k, v.shape if hasattr(v, 'shape') else v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b4a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Observation space\", env.observation_space)\n",
    "print(\"Action space\", env.action_space)\n",
    "\n",
    "# obs, _ = env.reset() # TODO: reset with a seed for determinism\n",
    "obs = env.reset() # TODO: reset with a seed for determinism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "done = False\n",
    "step = 0\n",
    "t0 = time.time()\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step({'action': action})\n",
    "    done = terminated or truncated\n",
    "    step += 1\n",
    "    # env.env.env.env.env.render() # maniskill render doesn't take any arguments, but the gymnasium environment does. Annoying.\n",
    "env.close()\n",
    "\n",
    "print(f\"{step} steps took {time.time() - t0}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b1bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
